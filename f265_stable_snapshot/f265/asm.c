// This file was auto-generated by snippets/asm.py.
// It handles the linkage of the assembly functions.

// Prototypes.
void f265_lbd_dct_4_c(int16_t *dst, uint8_t *src, int src_stride, uint8_t *pred, int pred_stride, uint8_t *spill);
void f265_lbd_dct_4_avx2(int16_t *dst, uint8_t *src, int src_stride, uint8_t *pred, int pred_stride, uint8_t *spill);
void f265_lbd_dct_8_c(int16_t *dst, uint8_t *src, int src_stride, uint8_t *pred, int pred_stride, uint8_t *spill);
void f265_lbd_dct_8_avx2(int16_t *dst, uint8_t *src, int src_stride, uint8_t *pred, int pred_stride, uint8_t *spill);
void f265_lbd_dct_16_c(int16_t *dst, uint8_t *src, int src_stride, uint8_t *pred, int pred_stride, uint8_t *spill);
void f265_lbd_dct_16_avx2(int16_t *dst, uint8_t *src, int src_stride, uint8_t *pred, int pred_stride, uint8_t *spill);
void f265_lbd_dct_32_c(int16_t *dst, uint8_t *src, int src_stride, uint8_t *pred, int pred_stride, uint8_t *spill);
void f265_lbd_dct_32_avx2(int16_t *dst, uint8_t *src, int src_stride, uint8_t *pred, int pred_stride, uint8_t *spill);
void f265_lbd_dct_dst_c(int16_t *dst, uint8_t *src, int src_stride, uint8_t *pred, int pred_stride, uint8_t *spill);
void f265_lbd_dct_dst_avx2(int16_t *dst, uint8_t *src, int src_stride, uint8_t *pred, int pred_stride, uint8_t *spill);
void f265_hbd_dct_4_c(int16_t *dst, int16_t *src, int src_stride, int16_t *pred, int pred_stride, uint8_t *spill);
void f265_hbd_dct_8_c(int16_t *dst, int16_t *src, int src_stride, int16_t *pred, int pred_stride, uint8_t *spill);
void f265_hbd_dct_16_c(int16_t *dst, int16_t *src, int src_stride, int16_t *pred, int pred_stride, uint8_t *spill);
void f265_hbd_dct_32_c(int16_t *dst, int16_t *src, int src_stride, int16_t *pred, int pred_stride, uint8_t *spill);
void f265_hbd_dct_dst_c(int16_t *dst, int16_t *src, int src_stride, int16_t *pred, int pred_stride, uint8_t *spill);

void f265_lbd_idct_4_c(uint8_t *dst, int dst_stride, uint8_t *pred, int pred_stride, int16_t *coeffs, uint8_t *spill);
void f265_lbd_idct_4_avx2(uint8_t *dst, int dst_stride, uint8_t *pred, int pred_stride, int16_t *coeffs, uint8_t *spill);
void f265_lbd_idct_8_c(uint8_t *dst, int dst_stride, uint8_t *pred, int pred_stride, int16_t *coeffs, uint8_t *spill);
void f265_lbd_idct_8_avx2(uint8_t *dst, int dst_stride, uint8_t *pred, int pred_stride, int16_t *coeffs, uint8_t *spill);
void f265_lbd_idct_16_c(uint8_t *dst, int dst_stride, uint8_t *pred, int pred_stride, int16_t *coeffs, uint8_t *spill);
void f265_lbd_idct_16_avx2(uint8_t *dst, int dst_stride, uint8_t *pred, int pred_stride, int16_t *coeffs, uint8_t *spill);
void f265_lbd_idct_32_c(uint8_t *dst, int dst_stride, uint8_t *pred, int pred_stride, int16_t *coeffs, uint8_t *spill);
void f265_lbd_idct_32_avx2(uint8_t *dst, int dst_stride, uint8_t *pred, int pred_stride, int16_t *coeffs, uint8_t *spill);
void f265_lbd_idct_dst_c(uint8_t *dst, int dst_stride, uint8_t *pred, int pred_stride, int16_t *coeffs, uint8_t *spill);
void f265_lbd_idct_dst_avx2(uint8_t *dst, int dst_stride, uint8_t *pred, int pred_stride, int16_t *coeffs, uint8_t *spill);
void f265_hbd_idct_4_c(int16_t *dst, int dst_stride, int16_t *pred, int pred_stride, int16_t *coeffs, uint8_t *spill);
void f265_hbd_idct_8_c(int16_t *dst, int dst_stride, int16_t *pred, int pred_stride, int16_t *coeffs, uint8_t *spill);
void f265_hbd_idct_16_c(int16_t *dst, int dst_stride, int16_t *pred, int pred_stride, int16_t *coeffs, uint8_t *spill);
void f265_hbd_idct_32_c(int16_t *dst, int dst_stride, int16_t *pred, int pred_stride, int16_t *coeffs, uint8_t *spill);
void f265_hbd_idct_dst_c(int16_t *dst, int dst_stride, int16_t *pred, int pred_stride, int16_t *coeffs, uint8_t *spill);

int f265_lbd_quant_c(int16_t *dst, int16_t *src, int bs, int mult, int add, int shift);
int f265_lbd_quant_4_avx2(int16_t *dst, int16_t *src, int bs, int mult, int add, int shift);
int f265_lbd_quant_8_avx2(int16_t *dst, int16_t *src, int bs, int mult, int add, int shift);
int f265_lbd_quant_16_avx2(int16_t *dst, int16_t *src, int bs, int mult, int add, int shift);
int f265_lbd_quant_32_avx2(int16_t *dst, int16_t *src, int bs, int mult, int add, int shift);
int f265_hbd_quant_c(int16_t *dst, int16_t *src, int bs, int mult, int add, int shift);

void f265_lbd_dequant_c(int16_t *dst, int16_t *src, int bs, int mult, int add, int shift);
void f265_lbd_dequant_4_avx2(int16_t *dst, int16_t *src, int bs, int mult, int add, int shift);
void f265_lbd_dequant_8_avx2(int16_t *dst, int16_t *src, int bs, int mult, int add, int shift);
void f265_lbd_dequant_16_avx2(int16_t *dst, int16_t *src, int bs, int mult, int add, int shift);
void f265_lbd_dequant_32_avx2(int16_t *dst, int16_t *src, int bs, int mult, int add, int shift);
void f265_hbd_dequant_c(int16_t *dst, int16_t *src, int bs, int mult, int add, int shift);

int f265_lbd_fsad_c(uint8_t *src, int src_stride, uint8_t *ref, int ref_stride, int packed_dims);
int f265_lbd_fsad_4_avx2(uint8_t *src, int src_stride, uint8_t *ref, int ref_stride, int packed_dims);
int f265_lbd_fsad_8_avx2(uint8_t *src, int src_stride, uint8_t *ref, int ref_stride, int packed_dims);
int f265_lbd_fsad_16_avx2(uint8_t *src, int src_stride, uint8_t *ref, int ref_stride, int packed_dims);
int f265_lbd_fsad_32_avx2(uint8_t *src, int src_stride, uint8_t *ref, int ref_stride, int packed_dims);
int f265_lbd_fsad_64_avx2(uint8_t *src, int src_stride, uint8_t *ref, int ref_stride, int packed_dims);
int f265_lbd_fsad_12_avx2(uint8_t *src, int src_stride, uint8_t *ref, int ref_stride, int packed_dims);
int f265_lbd_fsad_24_avx2(uint8_t *src, int src_stride, uint8_t *ref, int ref_stride, int packed_dims);
int f265_lbd_fsad_48_avx2(uint8_t *src, int src_stride, uint8_t *ref, int ref_stride, int packed_dims);
int f265_hbd_fsad_c(int16_t *src, int src_stride, int16_t *ref, int ref_stride, int packed_dims);

void f265_lbd_sad3_c(int *costs, uint8_t *src, int src_stride, uint8_t **refs, int ref_stride, int packed_dims);
void f265_lbd_sad3_4_avx2(int *costs, uint8_t *src, int src_stride, uint8_t **refs, int ref_stride, int packed_dims);
void f265_lbd_sad3_8_avx2(int *costs, uint8_t *src, int src_stride, uint8_t **refs, int ref_stride, int packed_dims);
void f265_lbd_sad3_16_avx2(int *costs, uint8_t *src, int src_stride, uint8_t **refs, int ref_stride, int packed_dims);
void f265_lbd_sad3_32_avx2(int *costs, uint8_t *src, int src_stride, uint8_t **refs, int ref_stride, int packed_dims);
void f265_lbd_sad3_64_avx2(int *costs, uint8_t *src, int src_stride, uint8_t **refs, int ref_stride, int packed_dims);
void f265_lbd_sad3_12_avx2(int *costs, uint8_t *src, int src_stride, uint8_t **refs, int ref_stride, int packed_dims);
void f265_lbd_sad3_24_avx2(int *costs, uint8_t *src, int src_stride, uint8_t **refs, int ref_stride, int packed_dims);
void f265_lbd_sad3_48_avx2(int *costs, uint8_t *src, int src_stride, uint8_t **refs, int ref_stride, int packed_dims);
void f265_hbd_sad3_c(int *costs, int16_t *src, int src_stride, int16_t **refs, int ref_stride, int packed_dims);

void f265_lbd_sad4_c(int *costs, uint8_t *src, int src_stride, uint8_t **refs, int ref_stride, int packed_dims);
void f265_lbd_sad4_4_avx2(int *costs, uint8_t *src, int src_stride, uint8_t **refs, int ref_stride, int packed_dims);
void f265_lbd_sad4_8_avx2(int *costs, uint8_t *src, int src_stride, uint8_t **refs, int ref_stride, int packed_dims);
void f265_lbd_sad4_16_avx2(int *costs, uint8_t *src, int src_stride, uint8_t **refs, int ref_stride, int packed_dims);
void f265_lbd_sad4_32_avx2(int *costs, uint8_t *src, int src_stride, uint8_t **refs, int ref_stride, int packed_dims);
void f265_lbd_sad4_64_avx2(int *costs, uint8_t *src, int src_stride, uint8_t **refs, int ref_stride, int packed_dims);
void f265_lbd_sad4_12_avx2(int *costs, uint8_t *src, int src_stride, uint8_t **refs, int ref_stride, int packed_dims);
void f265_lbd_sad4_24_avx2(int *costs, uint8_t *src, int src_stride, uint8_t **refs, int ref_stride, int packed_dims);
void f265_lbd_sad4_48_avx2(int *costs, uint8_t *src, int src_stride, uint8_t **refs, int ref_stride, int packed_dims);
void f265_hbd_sad4_c(int *costs, int16_t *src, int src_stride, int16_t **refs, int ref_stride, int packed_dims);

void f265_lbd_avg_pix_c(uint8_t *dst, uint8_t *src0, int src0_stride, uint8_t *src1, int src1_stride, int packed_dims);
void f265_lbd_avg_pix_4_avx2(uint8_t *dst, uint8_t *src0, int src0_stride, uint8_t *src1, int src1_stride, int packed_dims);
void f265_lbd_avg_pix_8_avx2(uint8_t *dst, uint8_t *src0, int src0_stride, uint8_t *src1, int src1_stride, int packed_dims);
void f265_lbd_avg_pix_16_avx2(uint8_t *dst, uint8_t *src0, int src0_stride, uint8_t *src1, int src1_stride, int packed_dims);
void f265_lbd_avg_pix_32_avx2(uint8_t *dst, uint8_t *src0, int src0_stride, uint8_t *src1, int src1_stride, int packed_dims);
void f265_lbd_avg_pix_64_avx2(uint8_t *dst, uint8_t *src0, int src0_stride, uint8_t *src1, int src1_stride, int packed_dims);
void f265_lbd_avg_pix_12_avx2(uint8_t *dst, uint8_t *src0, int src0_stride, uint8_t *src1, int src1_stride, int packed_dims);
void f265_lbd_avg_pix_24_avx2(uint8_t *dst, uint8_t *src0, int src0_stride, uint8_t *src1, int src1_stride, int packed_dims);
void f265_lbd_avg_pix_48_avx2(uint8_t *dst, uint8_t *src0, int src0_stride, uint8_t *src1, int src1_stride, int packed_dims);
void f265_hbd_avg_pix_c(int16_t *dst, int16_t *src0, int src0_stride, int16_t *src1, int src1_stride, int packed_dims);

void f265_lbd_interpol_luma_qpel_pix_h_c(uint8_t *dst, int dst_stride, uint8_t *src, int src_stride, int frac, int packed_dims, uint8_t *spill);
void f265_lbd_interpol_luma_qpel_pix_v_c(uint8_t *dst, int dst_stride, uint8_t *src, int src_stride, int frac, int packed_dims, uint8_t *spill);
void f265_lbd_interpol_luma_qpel_pix_d_c(uint8_t *dst, int dst_stride, uint8_t *src, int src_stride, int frac, int packed_dims, uint8_t *spill);
void f265_lbd_interpol_luma_qpel_pix_8_h_avx2(uint8_t *dst, int dst_stride, uint8_t *src, int src_stride, int frac, int packed_dims, uint8_t *spill);
void f265_lbd_interpol_luma_qpel_pix_8_v_avx2(uint8_t *dst, int dst_stride, uint8_t *src, int src_stride, int frac, int packed_dims, uint8_t *spill);
void f265_lbd_interpol_luma_qpel_pix_8_d_avx2(uint8_t *dst, int dst_stride, uint8_t *src, int src_stride, int frac, int packed_dims, uint8_t *spill);
void f265_lbd_interpol_luma_qpel_pix_16_h_avx2(uint8_t *dst, int dst_stride, uint8_t *src, int src_stride, int frac, int packed_dims, uint8_t *spill);
void f265_lbd_interpol_luma_qpel_pix_16_v_avx2(uint8_t *dst, int dst_stride, uint8_t *src, int src_stride, int frac, int packed_dims, uint8_t *spill);
void f265_lbd_interpol_luma_qpel_pix_16_d_avx2(uint8_t *dst, int dst_stride, uint8_t *src, int src_stride, int frac, int packed_dims, uint8_t *spill);
void f265_lbd_interpol_luma_qpel_pix_32_h_avx2(uint8_t *dst, int dst_stride, uint8_t *src, int src_stride, int frac, int packed_dims, uint8_t *spill);
void f265_lbd_interpol_luma_qpel_pix_32_v_avx2(uint8_t *dst, int dst_stride, uint8_t *src, int src_stride, int frac, int packed_dims, uint8_t *spill);
void f265_lbd_interpol_luma_qpel_pix_32_d_avx2(uint8_t *dst, int dst_stride, uint8_t *src, int src_stride, int frac, int packed_dims, uint8_t *spill);
void f265_lbd_interpol_luma_qpel_pix_64_h_avx2(uint8_t *dst, int dst_stride, uint8_t *src, int src_stride, int frac, int packed_dims, uint8_t *spill);
void f265_lbd_interpol_luma_qpel_pix_64_v_avx2(uint8_t *dst, int dst_stride, uint8_t *src, int src_stride, int frac, int packed_dims, uint8_t *spill);
void f265_lbd_interpol_luma_qpel_pix_64_d_avx2(uint8_t *dst, int dst_stride, uint8_t *src, int src_stride, int frac, int packed_dims, uint8_t *spill);
void f265_lbd_interpol_luma_qpel_pix_24_h_avx2(uint8_t *dst, int dst_stride, uint8_t *src, int src_stride, int frac, int packed_dims, uint8_t *spill);
void f265_lbd_interpol_luma_qpel_pix_24_v_avx2(uint8_t *dst, int dst_stride, uint8_t *src, int src_stride, int frac, int packed_dims, uint8_t *spill);
void f265_lbd_interpol_luma_qpel_pix_24_d_avx2(uint8_t *dst, int dst_stride, uint8_t *src, int src_stride, int frac, int packed_dims, uint8_t *spill);
void f265_lbd_interpol_luma_qpel_pix_48_h_avx2(uint8_t *dst, int dst_stride, uint8_t *src, int src_stride, int frac, int packed_dims, uint8_t *spill);
void f265_lbd_interpol_luma_qpel_pix_48_v_avx2(uint8_t *dst, int dst_stride, uint8_t *src, int src_stride, int frac, int packed_dims, uint8_t *spill);
void f265_lbd_interpol_luma_qpel_pix_48_d_avx2(uint8_t *dst, int dst_stride, uint8_t *src, int src_stride, int frac, int packed_dims, uint8_t *spill);
void f265_hbd_interpol_luma_qpel_pix_h_c(int16_t *dst, int dst_stride, int16_t *src, int src_stride, int frac, int packed_dims, uint8_t *spill);
void f265_hbd_interpol_luma_qpel_pix_v_c(int16_t *dst, int dst_stride, int16_t *src, int src_stride, int frac, int packed_dims, uint8_t *spill);
void f265_hbd_interpol_luma_qpel_pix_d_c(int16_t *dst, int dst_stride, int16_t *src, int src_stride, int frac, int packed_dims, uint8_t *spill);

// Special code.
#ifdef F265_HAVE_ASM
int f265_lbd_fsad_12_avx2(uint8_t *src, int src_stride, uint8_t *ref, int ref_stride, int packed_dims)
{
    return f265_lbd_fsad_8_avx2(src, src_stride, ref, ref_stride, packed_dims) +
           f265_lbd_fsad_4_avx2(src+8, src_stride, ref+8, ref_stride, packed_dims);
}

void f265_lbd_sad3_12_avx2(int *costs, uint8_t *src, int src_stride, uint8_t **refs, int ref_stride, int packed_dims)
{
    uint8_t *refs2[3] = { refs[0]+8, refs[1]+8, refs[2]+8 };
    int costs2[4];
    f265_lbd_sad3_8_avx2(costs, src, src_stride, refs, ref_stride, packed_dims);
    f265_lbd_sad3_4_avx2(costs2, src+8, src_stride, refs2, ref_stride, packed_dims);
    for (int i = 0; i < 3; i++) costs[i] += costs2[i];
}

void f265_lbd_sad4_12_avx2(int *costs, uint8_t *src, int src_stride, uint8_t **refs, int ref_stride, int packed_dims)
{
    uint8_t *refs2[4] = { refs[0]+8, refs[1]+8, refs[2]+8, refs[3]+8 };
    int costs2[4];
    f265_lbd_sad4_8_avx2(costs, src, src_stride, refs, ref_stride, packed_dims);
    f265_lbd_sad4_4_avx2(costs2, src+8, src_stride, refs2, ref_stride, packed_dims);
    for (int i = 0; i < 4; i++) costs[i] += costs2[i];
}

int f265_lbd_fsad_24_avx2(uint8_t *src, int src_stride, uint8_t *ref, int ref_stride, int packed_dims)
{
    return f265_lbd_fsad_16_avx2(src, src_stride, ref, ref_stride, packed_dims) +
           f265_lbd_fsad_8_avx2(src+16, src_stride, ref+16, ref_stride, packed_dims);
}

void f265_lbd_sad3_24_avx2(int *costs, uint8_t *src, int src_stride, uint8_t **refs, int ref_stride, int packed_dims)
{
    uint8_t *refs2[3] = { refs[0]+16, refs[1]+16, refs[2]+16 };
    int costs2[4];
    f265_lbd_sad3_16_avx2(costs, src, src_stride, refs, ref_stride, packed_dims);
    f265_lbd_sad3_8_avx2(costs2, src+16, src_stride, refs2, ref_stride, packed_dims);
    for (int i = 0; i < 3; i++) costs[i] += costs2[i];
}

void f265_lbd_sad4_24_avx2(int *costs, uint8_t *src, int src_stride, uint8_t **refs, int ref_stride, int packed_dims)
{
    uint8_t *refs2[4] = { refs[0]+16, refs[1]+16, refs[2]+16, refs[3]+16 };
    int costs2[4];
    f265_lbd_sad4_16_avx2(costs, src, src_stride, refs, ref_stride, packed_dims);
    f265_lbd_sad4_8_avx2(costs2, src+16, src_stride, refs2, ref_stride, packed_dims);
    for (int i = 0; i < 4; i++) costs[i] += costs2[i];
}

int f265_lbd_fsad_48_avx2(uint8_t *src, int src_stride, uint8_t *ref, int ref_stride, int packed_dims)
{
    return f265_lbd_fsad_32_avx2(src, src_stride, ref, ref_stride, packed_dims) +
           f265_lbd_fsad_16_avx2(src+32, src_stride, ref+32, ref_stride, packed_dims);
}

void f265_lbd_sad3_48_avx2(int *costs, uint8_t *src, int src_stride, uint8_t **refs, int ref_stride, int packed_dims)
{
    uint8_t *refs2[3] = { refs[0]+32, refs[1]+32, refs[2]+32 };
    int costs2[4];
    f265_lbd_sad3_32_avx2(costs, src, src_stride, refs, ref_stride, packed_dims);
    f265_lbd_sad3_16_avx2(costs2, src+32, src_stride, refs2, ref_stride, packed_dims);
    for (int i = 0; i < 3; i++) costs[i] += costs2[i];
}

void f265_lbd_sad4_48_avx2(int *costs, uint8_t *src, int src_stride, uint8_t **refs, int ref_stride, int packed_dims)
{
    uint8_t *refs2[4] = { refs[0]+32, refs[1]+32, refs[2]+32, refs[3]+32 };
    int costs2[4];
    f265_lbd_sad4_32_avx2(costs, src, src_stride, refs, ref_stride, packed_dims);
    f265_lbd_sad4_16_avx2(costs2, src+32, src_stride, refs2, ref_stride, packed_dims);
    for (int i = 0; i < 4; i++) costs[i] += costs2[i];
}

void f265_lbd_interpol_luma_qpel_pix_16_h_avx2(uint8_t *dst, int dst_stride, uint8_t *src, int src_stride, int frac,
                                               int packed_dims, uint8_t *spill)
{
    int nb_blocks = ((packed_dims>>8)&0xff)>>3;
    for (int i = 0; i < nb_blocks; i++)
        f265_lbd_interpol_luma_qpel_pix_8_h_avx2(dst + 8*i, dst_stride, src + 8*i, src_stride,
                                                 frac, packed_dims, spill);
}

void f265_lbd_interpol_luma_qpel_pix_16_v_avx2(uint8_t *dst, int dst_stride, uint8_t *src, int src_stride, int frac,
                                               int packed_dims, uint8_t *spill)
{
    int nb_blocks = ((packed_dims>>8)&0xff)>>3;
    for (int i = 0; i < nb_blocks; i++)
        f265_lbd_interpol_luma_qpel_pix_8_v_avx2(dst + 8*i, dst_stride, src + 8*i, src_stride,
                                                 frac, packed_dims, spill);
}

void f265_lbd_interpol_luma_qpel_pix_16_d_avx2(uint8_t *dst, int dst_stride, uint8_t *src, int src_stride, int frac,
                                               int packed_dims, uint8_t *spill)
{
    int nb_blocks = ((packed_dims>>8)&0xff)>>3;
    for (int i = 0; i < nb_blocks; i++)
        f265_lbd_interpol_luma_qpel_pix_8_d_avx2(dst + 8*i, dst_stride, src + 8*i, src_stride,
                                                 frac, packed_dims, spill);
}

void f265_lbd_interpol_luma_qpel_pix_32_h_avx2(uint8_t *dst, int dst_stride, uint8_t *src, int src_stride, int frac,
                                               int packed_dims, uint8_t *spill)
{
    int nb_blocks = ((packed_dims>>8)&0xff)>>3;
    for (int i = 0; i < nb_blocks; i++)
        f265_lbd_interpol_luma_qpel_pix_8_h_avx2(dst + 8*i, dst_stride, src + 8*i, src_stride,
                                                 frac, packed_dims, spill);
}

void f265_lbd_interpol_luma_qpel_pix_32_v_avx2(uint8_t *dst, int dst_stride, uint8_t *src, int src_stride, int frac,
                                               int packed_dims, uint8_t *spill)
{
    int nb_blocks = ((packed_dims>>8)&0xff)>>3;
    for (int i = 0; i < nb_blocks; i++)
        f265_lbd_interpol_luma_qpel_pix_8_v_avx2(dst + 8*i, dst_stride, src + 8*i, src_stride,
                                                 frac, packed_dims, spill);
}

void f265_lbd_interpol_luma_qpel_pix_32_d_avx2(uint8_t *dst, int dst_stride, uint8_t *src, int src_stride, int frac,
                                               int packed_dims, uint8_t *spill)
{
    int nb_blocks = ((packed_dims>>8)&0xff)>>3;
    for (int i = 0; i < nb_blocks; i++)
        f265_lbd_interpol_luma_qpel_pix_8_d_avx2(dst + 8*i, dst_stride, src + 8*i, src_stride,
                                                 frac, packed_dims, spill);
}

void f265_lbd_interpol_luma_qpel_pix_64_h_avx2(uint8_t *dst, int dst_stride, uint8_t *src, int src_stride, int frac,
                                               int packed_dims, uint8_t *spill)
{
    int nb_blocks = ((packed_dims>>8)&0xff)>>3;
    for (int i = 0; i < nb_blocks; i++)
        f265_lbd_interpol_luma_qpel_pix_8_h_avx2(dst + 8*i, dst_stride, src + 8*i, src_stride,
                                                 frac, packed_dims, spill);
}

void f265_lbd_interpol_luma_qpel_pix_64_v_avx2(uint8_t *dst, int dst_stride, uint8_t *src, int src_stride, int frac,
                                               int packed_dims, uint8_t *spill)
{
    int nb_blocks = ((packed_dims>>8)&0xff)>>3;
    for (int i = 0; i < nb_blocks; i++)
        f265_lbd_interpol_luma_qpel_pix_8_v_avx2(dst + 8*i, dst_stride, src + 8*i, src_stride,
                                                 frac, packed_dims, spill);
}

void f265_lbd_interpol_luma_qpel_pix_64_d_avx2(uint8_t *dst, int dst_stride, uint8_t *src, int src_stride, int frac,
                                               int packed_dims, uint8_t *spill)
{
    int nb_blocks = ((packed_dims>>8)&0xff)>>3;
    for (int i = 0; i < nb_blocks; i++)
        f265_lbd_interpol_luma_qpel_pix_8_d_avx2(dst + 8*i, dst_stride, src + 8*i, src_stride,
                                                 frac, packed_dims, spill);
}

void f265_lbd_interpol_luma_qpel_pix_24_h_avx2(uint8_t *dst, int dst_stride, uint8_t *src, int src_stride, int frac,
                                               int packed_dims, uint8_t *spill)
{
    int nb_blocks = ((packed_dims>>8)&0xff)>>3;
    for (int i = 0; i < nb_blocks; i++)
        f265_lbd_interpol_luma_qpel_pix_8_h_avx2(dst + 8*i, dst_stride, src + 8*i, src_stride,
                                                 frac, packed_dims, spill);
}

void f265_lbd_interpol_luma_qpel_pix_24_v_avx2(uint8_t *dst, int dst_stride, uint8_t *src, int src_stride, int frac,
                                               int packed_dims, uint8_t *spill)
{
    int nb_blocks = ((packed_dims>>8)&0xff)>>3;
    for (int i = 0; i < nb_blocks; i++)
        f265_lbd_interpol_luma_qpel_pix_8_v_avx2(dst + 8*i, dst_stride, src + 8*i, src_stride,
                                                 frac, packed_dims, spill);
}

void f265_lbd_interpol_luma_qpel_pix_24_d_avx2(uint8_t *dst, int dst_stride, uint8_t *src, int src_stride, int frac,
                                               int packed_dims, uint8_t *spill)
{
    int nb_blocks = ((packed_dims>>8)&0xff)>>3;
    for (int i = 0; i < nb_blocks; i++)
        f265_lbd_interpol_luma_qpel_pix_8_d_avx2(dst + 8*i, dst_stride, src + 8*i, src_stride,
                                                 frac, packed_dims, spill);
}

void f265_lbd_interpol_luma_qpel_pix_48_h_avx2(uint8_t *dst, int dst_stride, uint8_t *src, int src_stride, int frac,
                                               int packed_dims, uint8_t *spill)
{
    int nb_blocks = ((packed_dims>>8)&0xff)>>3;
    for (int i = 0; i < nb_blocks; i++)
        f265_lbd_interpol_luma_qpel_pix_8_h_avx2(dst + 8*i, dst_stride, src + 8*i, src_stride,
                                                 frac, packed_dims, spill);
}

void f265_lbd_interpol_luma_qpel_pix_48_v_avx2(uint8_t *dst, int dst_stride, uint8_t *src, int src_stride, int frac,
                                               int packed_dims, uint8_t *spill)
{
    int nb_blocks = ((packed_dims>>8)&0xff)>>3;
    for (int i = 0; i < nb_blocks; i++)
        f265_lbd_interpol_luma_qpel_pix_8_v_avx2(dst + 8*i, dst_stride, src + 8*i, src_stride,
                                                 frac, packed_dims, spill);
}

void f265_lbd_interpol_luma_qpel_pix_48_d_avx2(uint8_t *dst, int dst_stride, uint8_t *src, int src_stride, int frac,
                                               int packed_dims, uint8_t *spill)
{
    int nb_blocks = ((packed_dims>>8)&0xff)>>3;
    for (int i = 0; i < nb_blocks; i++)
        f265_lbd_interpol_luma_qpel_pix_8_d_avx2(dst + 8*i, dst_stride, src + 8*i, src_stride,
                                                 frac, packed_dims, spill);
}

#endif

// Globals.
f265_lbd_dct_func f265_lbd_dct[5];
f265_lbd_idct_func f265_lbd_idct[5];
f265_lbd_quant_func f265_lbd_quant[4];
f265_lbd_dequant_func f265_lbd_dequant[4];
f265_lbd_fsad_func f265_lbd_fsad[10];
f265_lbd_sad3_func f265_lbd_sad3[10];
f265_lbd_sad4_func f265_lbd_sad4[10];
f265_lbd_avg_pix_func f265_lbd_avg_pix[10];
f265_lbd_interpol_luma_qpel_pix_func f265_lbd_interpol_luma_qpel_pix[30];

f265_hbd_dct_func f265_hbd_dct[5];
f265_hbd_idct_func f265_hbd_idct[5];
f265_hbd_quant_func f265_hbd_quant[4];
f265_hbd_dequant_func f265_hbd_dequant[4];
f265_hbd_fsad_func f265_hbd_fsad[10];
f265_hbd_sad3_func f265_hbd_sad3[10];
f265_hbd_sad4_func f265_hbd_sad4[10];
f265_hbd_avg_pix_func f265_hbd_avg_pix[10];
f265_hbd_interpol_luma_qpel_pix_func f265_hbd_interpol_luma_qpel_pix[30];

// Linkage at runtime.
static void f265_link_asm(int avx2_flag)
{
    f265_lbd_dct[0] = f265_lbd_dct_4_c;
    f265_lbd_dct[1] = f265_lbd_dct_8_c;
    f265_lbd_dct[2] = f265_lbd_dct_16_c;
    f265_lbd_dct[3] = f265_lbd_dct_32_c;
    f265_lbd_dct[4] = f265_lbd_dct_dst_c;
    f265_hbd_dct[0] = f265_hbd_dct_4_c;
    f265_hbd_dct[1] = f265_hbd_dct_8_c;
    f265_hbd_dct[2] = f265_hbd_dct_16_c;
    f265_hbd_dct[3] = f265_hbd_dct_32_c;
    f265_hbd_dct[4] = f265_hbd_dct_dst_c;
    f265_lbd_idct[0] = f265_lbd_idct_4_c;
    f265_lbd_idct[1] = f265_lbd_idct_8_c;
    f265_lbd_idct[2] = f265_lbd_idct_16_c;
    f265_lbd_idct[3] = f265_lbd_idct_32_c;
    f265_lbd_idct[4] = f265_lbd_idct_dst_c;
    f265_hbd_idct[0] = f265_hbd_idct_4_c;
    f265_hbd_idct[1] = f265_hbd_idct_8_c;
    f265_hbd_idct[2] = f265_hbd_idct_16_c;
    f265_hbd_idct[3] = f265_hbd_idct_32_c;
    f265_hbd_idct[4] = f265_hbd_idct_dst_c;
    f265_lbd_quant[0] = f265_lbd_quant_c;
    f265_lbd_quant[1] = f265_lbd_quant_c;
    f265_lbd_quant[2] = f265_lbd_quant_c;
    f265_lbd_quant[3] = f265_lbd_quant_c;
    f265_hbd_quant[0] = f265_hbd_quant_c;
    f265_hbd_quant[1] = f265_hbd_quant_c;
    f265_hbd_quant[2] = f265_hbd_quant_c;
    f265_hbd_quant[3] = f265_hbd_quant_c;
    f265_lbd_dequant[0] = f265_lbd_dequant_c;
    f265_lbd_dequant[1] = f265_lbd_dequant_c;
    f265_lbd_dequant[2] = f265_lbd_dequant_c;
    f265_lbd_dequant[3] = f265_lbd_dequant_c;
    f265_hbd_dequant[0] = f265_hbd_dequant_c;
    f265_hbd_dequant[1] = f265_hbd_dequant_c;
    f265_hbd_dequant[2] = f265_hbd_dequant_c;
    f265_hbd_dequant[3] = f265_hbd_dequant_c;
    f265_lbd_fsad[0] = f265_lbd_fsad_c;
    f265_lbd_fsad[1] = f265_lbd_fsad_c;
    f265_lbd_fsad[2] = f265_lbd_fsad_c;
    f265_lbd_fsad[3] = f265_lbd_fsad_c;
    f265_lbd_fsad[4] = f265_lbd_fsad_c;
    f265_lbd_fsad[5] = f265_lbd_fsad_c;
    f265_lbd_fsad[6] = f265_lbd_fsad_c;
    f265_lbd_fsad[7] = f265_lbd_fsad_c;
    f265_lbd_fsad[8] = f265_lbd_fsad_c;
    f265_lbd_fsad[9] = f265_lbd_fsad_c;
    f265_hbd_fsad[0] = f265_hbd_fsad_c;
    f265_hbd_fsad[1] = f265_hbd_fsad_c;
    f265_hbd_fsad[2] = f265_hbd_fsad_c;
    f265_hbd_fsad[3] = f265_hbd_fsad_c;
    f265_hbd_fsad[4] = f265_hbd_fsad_c;
    f265_hbd_fsad[5] = f265_hbd_fsad_c;
    f265_hbd_fsad[6] = f265_hbd_fsad_c;
    f265_hbd_fsad[7] = f265_hbd_fsad_c;
    f265_hbd_fsad[8] = f265_hbd_fsad_c;
    f265_hbd_fsad[9] = f265_hbd_fsad_c;
    f265_lbd_sad3[1] = f265_lbd_sad3_c;
    f265_lbd_sad3[2] = f265_lbd_sad3_c;
    f265_lbd_sad3[3] = f265_lbd_sad3_c;
    f265_lbd_sad3[4] = f265_lbd_sad3_c;
    f265_lbd_sad3[5] = f265_lbd_sad3_c;
    f265_lbd_sad3[7] = f265_lbd_sad3_c;
    f265_lbd_sad3[8] = f265_lbd_sad3_c;
    f265_lbd_sad3[9] = f265_lbd_sad3_c;
    f265_hbd_sad3[1] = f265_hbd_sad3_c;
    f265_hbd_sad3[2] = f265_hbd_sad3_c;
    f265_hbd_sad3[3] = f265_hbd_sad3_c;
    f265_hbd_sad3[4] = f265_hbd_sad3_c;
    f265_hbd_sad3[5] = f265_hbd_sad3_c;
    f265_hbd_sad3[7] = f265_hbd_sad3_c;
    f265_hbd_sad3[8] = f265_hbd_sad3_c;
    f265_hbd_sad3[9] = f265_hbd_sad3_c;
    f265_lbd_sad4[1] = f265_lbd_sad4_c;
    f265_lbd_sad4[2] = f265_lbd_sad4_c;
    f265_lbd_sad4[3] = f265_lbd_sad4_c;
    f265_lbd_sad4[4] = f265_lbd_sad4_c;
    f265_lbd_sad4[5] = f265_lbd_sad4_c;
    f265_lbd_sad4[7] = f265_lbd_sad4_c;
    f265_lbd_sad4[8] = f265_lbd_sad4_c;
    f265_lbd_sad4[9] = f265_lbd_sad4_c;
    f265_hbd_sad4[1] = f265_hbd_sad4_c;
    f265_hbd_sad4[2] = f265_hbd_sad4_c;
    f265_hbd_sad4[3] = f265_hbd_sad4_c;
    f265_hbd_sad4[4] = f265_hbd_sad4_c;
    f265_hbd_sad4[5] = f265_hbd_sad4_c;
    f265_hbd_sad4[7] = f265_hbd_sad4_c;
    f265_hbd_sad4[8] = f265_hbd_sad4_c;
    f265_hbd_sad4[9] = f265_hbd_sad4_c;
    f265_lbd_avg_pix[1] = f265_lbd_avg_pix_c;
    f265_lbd_avg_pix[2] = f265_lbd_avg_pix_c;
    f265_lbd_avg_pix[3] = f265_lbd_avg_pix_c;
    f265_lbd_avg_pix[4] = f265_lbd_avg_pix_c;
    f265_lbd_avg_pix[5] = f265_lbd_avg_pix_c;
    f265_lbd_avg_pix[7] = f265_lbd_avg_pix_c;
    f265_lbd_avg_pix[8] = f265_lbd_avg_pix_c;
    f265_lbd_avg_pix[9] = f265_lbd_avg_pix_c;
    f265_hbd_avg_pix[1] = f265_hbd_avg_pix_c;
    f265_hbd_avg_pix[2] = f265_hbd_avg_pix_c;
    f265_hbd_avg_pix[3] = f265_hbd_avg_pix_c;
    f265_hbd_avg_pix[4] = f265_hbd_avg_pix_c;
    f265_hbd_avg_pix[5] = f265_hbd_avg_pix_c;
    f265_hbd_avg_pix[7] = f265_hbd_avg_pix_c;
    f265_hbd_avg_pix[8] = f265_hbd_avg_pix_c;
    f265_hbd_avg_pix[9] = f265_hbd_avg_pix_c;
    f265_lbd_interpol_luma_qpel_pix[3] = f265_lbd_interpol_luma_qpel_pix_h_c;
    f265_lbd_interpol_luma_qpel_pix[4] = f265_lbd_interpol_luma_qpel_pix_v_c;
    f265_lbd_interpol_luma_qpel_pix[5] = f265_lbd_interpol_luma_qpel_pix_d_c;
    f265_lbd_interpol_luma_qpel_pix[6] = f265_lbd_interpol_luma_qpel_pix_h_c;
    f265_lbd_interpol_luma_qpel_pix[7] = f265_lbd_interpol_luma_qpel_pix_v_c;
    f265_lbd_interpol_luma_qpel_pix[8] = f265_lbd_interpol_luma_qpel_pix_d_c;
    f265_lbd_interpol_luma_qpel_pix[9] = f265_lbd_interpol_luma_qpel_pix_h_c;
    f265_lbd_interpol_luma_qpel_pix[10] = f265_lbd_interpol_luma_qpel_pix_v_c;
    f265_lbd_interpol_luma_qpel_pix[11] = f265_lbd_interpol_luma_qpel_pix_d_c;
    f265_lbd_interpol_luma_qpel_pix[12] = f265_lbd_interpol_luma_qpel_pix_h_c;
    f265_lbd_interpol_luma_qpel_pix[13] = f265_lbd_interpol_luma_qpel_pix_v_c;
    f265_lbd_interpol_luma_qpel_pix[14] = f265_lbd_interpol_luma_qpel_pix_d_c;
    f265_lbd_interpol_luma_qpel_pix[15] = f265_lbd_interpol_luma_qpel_pix_h_c;
    f265_lbd_interpol_luma_qpel_pix[16] = f265_lbd_interpol_luma_qpel_pix_v_c;
    f265_lbd_interpol_luma_qpel_pix[17] = f265_lbd_interpol_luma_qpel_pix_d_c;
    f265_lbd_interpol_luma_qpel_pix[21] = f265_lbd_interpol_luma_qpel_pix_h_c;
    f265_lbd_interpol_luma_qpel_pix[22] = f265_lbd_interpol_luma_qpel_pix_v_c;
    f265_lbd_interpol_luma_qpel_pix[23] = f265_lbd_interpol_luma_qpel_pix_d_c;
    f265_lbd_interpol_luma_qpel_pix[24] = f265_lbd_interpol_luma_qpel_pix_h_c;
    f265_lbd_interpol_luma_qpel_pix[25] = f265_lbd_interpol_luma_qpel_pix_v_c;
    f265_lbd_interpol_luma_qpel_pix[26] = f265_lbd_interpol_luma_qpel_pix_d_c;
    f265_lbd_interpol_luma_qpel_pix[27] = f265_lbd_interpol_luma_qpel_pix_h_c;
    f265_lbd_interpol_luma_qpel_pix[28] = f265_lbd_interpol_luma_qpel_pix_v_c;
    f265_lbd_interpol_luma_qpel_pix[29] = f265_lbd_interpol_luma_qpel_pix_d_c;
    f265_hbd_interpol_luma_qpel_pix[3] = f265_hbd_interpol_luma_qpel_pix_h_c;
    f265_hbd_interpol_luma_qpel_pix[4] = f265_hbd_interpol_luma_qpel_pix_v_c;
    f265_hbd_interpol_luma_qpel_pix[5] = f265_hbd_interpol_luma_qpel_pix_d_c;
    f265_hbd_interpol_luma_qpel_pix[6] = f265_hbd_interpol_luma_qpel_pix_h_c;
    f265_hbd_interpol_luma_qpel_pix[7] = f265_hbd_interpol_luma_qpel_pix_v_c;
    f265_hbd_interpol_luma_qpel_pix[8] = f265_hbd_interpol_luma_qpel_pix_d_c;
    f265_hbd_interpol_luma_qpel_pix[9] = f265_hbd_interpol_luma_qpel_pix_h_c;
    f265_hbd_interpol_luma_qpel_pix[10] = f265_hbd_interpol_luma_qpel_pix_v_c;
    f265_hbd_interpol_luma_qpel_pix[11] = f265_hbd_interpol_luma_qpel_pix_d_c;
    f265_hbd_interpol_luma_qpel_pix[12] = f265_hbd_interpol_luma_qpel_pix_h_c;
    f265_hbd_interpol_luma_qpel_pix[13] = f265_hbd_interpol_luma_qpel_pix_v_c;
    f265_hbd_interpol_luma_qpel_pix[14] = f265_hbd_interpol_luma_qpel_pix_d_c;
    f265_hbd_interpol_luma_qpel_pix[15] = f265_hbd_interpol_luma_qpel_pix_h_c;
    f265_hbd_interpol_luma_qpel_pix[16] = f265_hbd_interpol_luma_qpel_pix_v_c;
    f265_hbd_interpol_luma_qpel_pix[17] = f265_hbd_interpol_luma_qpel_pix_d_c;
    f265_hbd_interpol_luma_qpel_pix[21] = f265_hbd_interpol_luma_qpel_pix_h_c;
    f265_hbd_interpol_luma_qpel_pix[22] = f265_hbd_interpol_luma_qpel_pix_v_c;
    f265_hbd_interpol_luma_qpel_pix[23] = f265_hbd_interpol_luma_qpel_pix_d_c;
    f265_hbd_interpol_luma_qpel_pix[24] = f265_hbd_interpol_luma_qpel_pix_h_c;
    f265_hbd_interpol_luma_qpel_pix[25] = f265_hbd_interpol_luma_qpel_pix_v_c;
    f265_hbd_interpol_luma_qpel_pix[26] = f265_hbd_interpol_luma_qpel_pix_d_c;
    f265_hbd_interpol_luma_qpel_pix[27] = f265_hbd_interpol_luma_qpel_pix_h_c;
    f265_hbd_interpol_luma_qpel_pix[28] = f265_hbd_interpol_luma_qpel_pix_v_c;
    f265_hbd_interpol_luma_qpel_pix[29] = f265_hbd_interpol_luma_qpel_pix_d_c;

    #ifdef F265_HAVE_ASM
    if (avx2_flag)
    {
        f265_lbd_dct[0] = f265_lbd_dct_4_avx2;
        f265_lbd_dct[1] = f265_lbd_dct_8_avx2;
        f265_lbd_dct[2] = f265_lbd_dct_16_avx2;
        f265_lbd_dct[3] = f265_lbd_dct_32_avx2;
        f265_lbd_dct[4] = f265_lbd_dct_dst_avx2;
        f265_lbd_idct[0] = f265_lbd_idct_4_avx2;
        f265_lbd_idct[1] = f265_lbd_idct_8_avx2;
        f265_lbd_idct[2] = f265_lbd_idct_16_avx2;
        f265_lbd_idct[3] = f265_lbd_idct_32_avx2;
        f265_lbd_idct[4] = f265_lbd_idct_dst_avx2;
        f265_lbd_quant[0] = f265_lbd_quant_4_avx2;
        f265_lbd_quant[1] = f265_lbd_quant_8_avx2;
        f265_lbd_quant[2] = f265_lbd_quant_16_avx2;
        f265_lbd_quant[3] = f265_lbd_quant_32_avx2;
        f265_lbd_dequant[0] = f265_lbd_dequant_4_avx2;
        f265_lbd_dequant[1] = f265_lbd_dequant_8_avx2;
        f265_lbd_dequant[2] = f265_lbd_dequant_16_avx2;
        f265_lbd_dequant[3] = f265_lbd_dequant_32_avx2;
        f265_lbd_fsad[1] = f265_lbd_fsad_4_avx2;
        f265_lbd_fsad[2] = f265_lbd_fsad_8_avx2;
        f265_lbd_fsad[3] = f265_lbd_fsad_16_avx2;
        f265_lbd_fsad[4] = f265_lbd_fsad_32_avx2;
        f265_lbd_fsad[5] = f265_lbd_fsad_64_avx2;
        f265_lbd_fsad[7] = f265_lbd_fsad_12_avx2;
        f265_lbd_fsad[8] = f265_lbd_fsad_24_avx2;
        f265_lbd_fsad[9] = f265_lbd_fsad_48_avx2;
        f265_lbd_sad3[1] = f265_lbd_sad3_4_avx2;
        f265_lbd_sad3[2] = f265_lbd_sad3_8_avx2;
        f265_lbd_sad3[3] = f265_lbd_sad3_16_avx2;
        f265_lbd_sad3[4] = f265_lbd_sad3_32_avx2;
        f265_lbd_sad3[5] = f265_lbd_sad3_64_avx2;
        f265_lbd_sad3[7] = f265_lbd_sad3_12_avx2;
        f265_lbd_sad3[8] = f265_lbd_sad3_24_avx2;
        f265_lbd_sad3[9] = f265_lbd_sad3_48_avx2;
        f265_lbd_sad4[1] = f265_lbd_sad4_4_avx2;
        f265_lbd_sad4[2] = f265_lbd_sad4_8_avx2;
        f265_lbd_sad4[3] = f265_lbd_sad4_16_avx2;
        f265_lbd_sad4[4] = f265_lbd_sad4_32_avx2;
        f265_lbd_sad4[5] = f265_lbd_sad4_64_avx2;
        f265_lbd_sad4[7] = f265_lbd_sad4_12_avx2;
        f265_lbd_sad4[8] = f265_lbd_sad4_24_avx2;
        f265_lbd_sad4[9] = f265_lbd_sad4_48_avx2;
        f265_lbd_avg_pix[1] = f265_lbd_avg_pix_4_avx2;
        f265_lbd_avg_pix[2] = f265_lbd_avg_pix_8_avx2;
        f265_lbd_avg_pix[3] = f265_lbd_avg_pix_16_avx2;
        f265_lbd_avg_pix[4] = f265_lbd_avg_pix_32_avx2;
        f265_lbd_avg_pix[5] = f265_lbd_avg_pix_64_avx2;
        f265_lbd_avg_pix[7] = f265_lbd_avg_pix_12_avx2;
        f265_lbd_avg_pix[8] = f265_lbd_avg_pix_24_avx2;
        f265_lbd_avg_pix[9] = f265_lbd_avg_pix_48_avx2;
        f265_lbd_interpol_luma_qpel_pix[6] = f265_lbd_interpol_luma_qpel_pix_8_h_avx2;
        f265_lbd_interpol_luma_qpel_pix[7] = f265_lbd_interpol_luma_qpel_pix_8_v_avx2;
        f265_lbd_interpol_luma_qpel_pix[8] = f265_lbd_interpol_luma_qpel_pix_8_d_avx2;
        f265_lbd_interpol_luma_qpel_pix[9] = f265_lbd_interpol_luma_qpel_pix_16_h_avx2;
        f265_lbd_interpol_luma_qpel_pix[10] = f265_lbd_interpol_luma_qpel_pix_16_v_avx2;
        f265_lbd_interpol_luma_qpel_pix[11] = f265_lbd_interpol_luma_qpel_pix_16_d_avx2;
        f265_lbd_interpol_luma_qpel_pix[12] = f265_lbd_interpol_luma_qpel_pix_32_h_avx2;
        f265_lbd_interpol_luma_qpel_pix[13] = f265_lbd_interpol_luma_qpel_pix_32_v_avx2;
        f265_lbd_interpol_luma_qpel_pix[14] = f265_lbd_interpol_luma_qpel_pix_32_d_avx2;
        f265_lbd_interpol_luma_qpel_pix[15] = f265_lbd_interpol_luma_qpel_pix_64_h_avx2;
        f265_lbd_interpol_luma_qpel_pix[16] = f265_lbd_interpol_luma_qpel_pix_64_v_avx2;
        f265_lbd_interpol_luma_qpel_pix[17] = f265_lbd_interpol_luma_qpel_pix_64_d_avx2;
        f265_lbd_interpol_luma_qpel_pix[24] = f265_lbd_interpol_luma_qpel_pix_24_h_avx2;
        f265_lbd_interpol_luma_qpel_pix[25] = f265_lbd_interpol_luma_qpel_pix_24_v_avx2;
        f265_lbd_interpol_luma_qpel_pix[26] = f265_lbd_interpol_luma_qpel_pix_24_d_avx2;
        f265_lbd_interpol_luma_qpel_pix[27] = f265_lbd_interpol_luma_qpel_pix_48_h_avx2;
        f265_lbd_interpol_luma_qpel_pix[28] = f265_lbd_interpol_luma_qpel_pix_48_v_avx2;
        f265_lbd_interpol_luma_qpel_pix[29] = f265_lbd_interpol_luma_qpel_pix_48_d_avx2;
    }
    #endif
}

